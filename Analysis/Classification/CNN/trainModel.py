#
# This code is available under a GPL v3.0 license and comes without
# any explicit or implicit warranty.
#
# (C) Wilfried Woeber 2020 <wilfried.woeber@technikum-wien.at>
import tensorflow as tf
from tensorflow.keras.applications import VGG16    #Import the VGG capabilities
from tensorflow.keras import models                #Import models --> several layers
from tensorflow.keras import layers                #Layers :-)
from tensorflow.keras import optimizers            #Keras optimizer
from tensorflow.keras.preprocessing.image import ImageDataGenerator #Data generator for augmention
from tensorflow.keras.layers import Input, Flatten, Dense, Dropout
from tensorflow.keras.models import Model
from sklearn.metrics import confusion_matrix        #Confusion matrix
import sys 
import numpy as np
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)

#import tensorflow.compat.v1 as tf
#tf.disable_v2_behavior()

#------------------------------#
#--- Define global settings ---#
#------------------------------#
if(len(sys.argv) == 1):
    sys.argv=['./trainModel.py','1']
train_dir="./CNNData/Train"         #Train folder generated by bash script
validation_dir="./CNNData/Test"     #Test folder generated by test script
image_size=64               #Image size of VGG
train_batchsize = 8         #Used batches for training
val_batchsize = 5           #Validation batchsize
epochs=50                  #Epochs
Augmention=True             #Get augmention flag
print("Augmention:", Augmention)
#--------------------------#
#--- Load the VGG model ---#
#--------------------------#
vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))
#--- Freeze the layers except the last 4 layers ---#
for layer in vgg_conv.layers[:-4]:
    layer.trainable = False
#--- Check the trainable status of the individual layers ---#
#for layer in vgg_conv.layers:
#    print(layer, layer.trainable)
#------------------------#
#--- Create the model ---#
#------------------------#
#--- We have to do this cuz of Keras-viz ---#
last = vgg_conv.output
x = Flatten()(last)
x= Dense(1024,activation='relu')(x)
x=Dropout(0.5)(x)
pred=Dense(2,activation='softmax')(x)
model = Model(vgg_conv.input,pred)
#---  Show a summary of the model ---#
model.summary()
#-----------------------------------#
#--- Define trainign environment ---#
#-----------------------------------#
#--- Image data generators ---#
if(Augmention):
    train_datagen = ImageDataGenerator(                     #Augmention
        rescale=1./255,
          rotation_range=20,
          width_shift_range=0.2,
          height_shift_range=0.2,
          horizontal_flip=True,
          fill_mode='nearest')
else:
    train_datagen = ImageDataGenerator(rescale=1./255)     #No augmention
validation_datagen = ImageDataGenerator(rescale=1./255)
#--- Get generators ---#
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_size, image_size),
        batch_size=train_batchsize,
        class_mode='categorical')
#validation_generator = validation_datagen.flow_from_directory(
#        validation_dir,
#        target_size=(image_size, image_size),
#        batch_size=val_batchsize,
#        class_mode='categorical',
#        shuffle=False)
#-------------------#
#--- Train model ---#
#-------------------#
model.compile(loss='categorical_crossentropy',
             optimizer=optimizers.RMSprop(lr=1e-4),
             metrics=['acc'])
history = model.fit_generator(
      train_generator,
      steps_per_epoch=train_generator.samples/train_generator.batch_size ,
      epochs=epochs,
      #validation_data=validation_generator,
      #validation_steps=validation_generator.samples/validation_generator.batch_size,
      verbose=1)
#model.load_weights('CNNmodel') #UNCOMMENT this line if you want to load a model
#-------------------#
#--- Store model ---#
#-------------------#
#print('Accuracy_fin:',history.history['val_acc'][-1])   #Print accuracy
#------------------#
#--- Test model ---#
#------------------#
train_im = ImageDataGenerator(rescale=1./255)
def test_images():
    train_generator = train_im.flow_from_directory (
            validation_dir, 
            target_size=(image_size, image_size),
            color_mode='rgb',
            batch_size=104,
            shuffle = False,
            class_mode='categorical'
         )
    x =  train_generator
    #return x[0][0], x[0][1], train_generator.filenames
    return x, train_generator.filenames
test_data = test_images()
#--- Do predcition ---#
prediction = model.predict(test_data[0])
prediction_row = np.argmax(prediction,1)
#--- Get ground truth and CM ---#
GT = np.array(()) #Get empty array
for i in range(0,len(test_data[0])):
    GT = np.concatenate((GT,test_data[0][i][1][:,1]))
#groundTruth_row = np.argmax(test_data[1],1)
CM = confusion_matrix(prediction_row, GT)
print(CM)
#-------------------#
#--- Store stuff ---#
#-------------------#
np.savetxt("CM.csv", CM)
np.savetxt("loss.csv", history.history['loss'])
np.savetxt("label_prediction.csv", prediction_row)
np.savetxt("label_groundTruth.csv", GT)
np.savetxt("label_predIDs.csv", test_data[1], fmt="%s")
np.savetxt("label_predProb.csv", prediction)
model.save("CNNmodel")
